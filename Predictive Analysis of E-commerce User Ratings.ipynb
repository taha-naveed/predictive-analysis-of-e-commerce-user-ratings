{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Z88FfJc9lA_T",
   "metadata": {
    "id": "Z88FfJc9lA_T"
   },
   "source": [
    "## Analysis of an E-commerce Dataset Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637eb9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_name = \"Taha Naveed Shibli\"\n",
    "student_id = \"47892641\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hoq0NwA9lA_V",
   "metadata": {
    "id": "hoq0NwA9lA_V"
   },
   "source": [
    "The goal of the second analysis task is to train linear regression models to predict users' ratings towards items. This involves a standard Data Science workflow: exploring data, building models, making predictions, and evaluating results. In this task, we will explore the impacts of feature selections and different sizes of training/testing data on the model performance. We will use another cleaned combined e-commerce sub-dataset that **is different from** the one in “Analysis of an E-commerce Dataset” task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fd3NU_lA_W",
   "metadata": {
    "id": "f9fd3NU_lA_W"
   },
   "source": [
    "### Import Cleaned E-commerce Dataset\n",
    "The csv file named 'cleaned_ecommerce_dataset.csv' is provided. You may need to use the Pandas method, i.e., `read_csv`, for reading it. After that, please print out its total length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "PJrb2gtAlA_W",
   "metadata": {
    "id": "PJrb2gtAlA_W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show the length of the dataframe: ecommerce_df\n",
      "2685\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "ecommerce_ds = 'cleaned_ecommerce_dataset.csv'\n",
    "ecommerce_df = pd.read_csv(ecommerce_ds)\n",
    "print('show the length of the dataframe: ecommerce_df')\n",
    "print(len(ecommerce_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aqbuU6rglA_X",
   "metadata": {
    "id": "aqbuU6rglA_X"
   },
   "source": [
    "### Explore the Dataset\n",
    "\n",
    "* Use the methods, i.e., `head()` and `info()`, to have a rough picture about the data, e.g., how many columns, and the data types of each column.\n",
    "* As our goal is to predict ratings given other columns, please get the correlations between helpfulness/gender/category/review and rating by using the `corr()` method.\n",
    "* To get the correlations between different features, you may need to first convert the categorical features (i.e., gender, category and review) into numerial values. For doing this, you may need to import `OrdinalEncoder` from `sklearn.preprocessing` (refer to the useful exmaples [here](https://pbpython.com/categorical-encoding.html))\n",
    "* Please provide ___necessary explanations/analysis___ on the correlations, and figure out which are the ___most___ and ___least___ corrleated features regarding rating. Try to ___discuss___ how the correlation will affect the final prediction results, if we use these features to train a regression model for rating prediction. In what follows, we will conduct experiments to verify your hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "W3PImHiElA_X",
   "metadata": {
    "id": "W3PImHiElA_X"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>review</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>gender</th>\n",
       "      <th>category</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>user_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4081</td>\n",
       "      <td>71900</td>\n",
       "      <td>Not always McCrap</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>41</td>\n",
       "      <td>30.74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4081</td>\n",
       "      <td>72000</td>\n",
       "      <td>I dropped the chalupa even before he told me to</td>\n",
       "      <td>Taco Bell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>74</td>\n",
       "      <td>108.30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4081</td>\n",
       "      <td>72000</td>\n",
       "      <td>The Wonderful World of Wendy</td>\n",
       "      <td>Wendy's</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>84</td>\n",
       "      <td>69.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4081</td>\n",
       "      <td>100399</td>\n",
       "      <td>They actually did it</td>\n",
       "      <td>South Park: Bigger, Longer &amp; Uncut</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>68</td>\n",
       "      <td>143.11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4081</td>\n",
       "      <td>100399</td>\n",
       "      <td>Hey! Gimme some pie!</td>\n",
       "      <td>American Pie</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>6</td>\n",
       "      <td>117.89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4081</td>\n",
       "      <td>100399</td>\n",
       "      <td>Good for sci-fi</td>\n",
       "      <td>Matrix</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>40</td>\n",
       "      <td>24.51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4081</td>\n",
       "      <td>100399</td>\n",
       "      <td>Scary? you bet!</td>\n",
       "      <td>Blair Witch Project</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>12</td>\n",
       "      <td>44.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4081</td>\n",
       "      <td>101899</td>\n",
       "      <td>Fox - the 4th basic channel</td>\n",
       "      <td>FOX</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Media</td>\n",
       "      <td>25</td>\n",
       "      <td>80.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4081</td>\n",
       "      <td>112099</td>\n",
       "      <td>Amen!</td>\n",
       "      <td>Dogma</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Movies</td>\n",
       "      <td>22</td>\n",
       "      <td>87.59</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4081</td>\n",
       "      <td>122899</td>\n",
       "      <td>mama mia!</td>\n",
       "      <td>Olive Garden</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Restaurants &amp; Gourmet</td>\n",
       "      <td>49</td>\n",
       "      <td>32.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  timestamp                                           review  \\\n",
       "0    4081      71900                                Not always McCrap   \n",
       "1    4081      72000  I dropped the chalupa even before he told me to   \n",
       "2    4081      72000                     The Wonderful World of Wendy   \n",
       "3    4081     100399                             They actually did it   \n",
       "4    4081     100399                             Hey! Gimme some pie!   \n",
       "5    4081     100399                                  Good for sci-fi   \n",
       "6    4081     100399                                  Scary? you bet!   \n",
       "7    4081     101899                      Fox - the 4th basic channel   \n",
       "8    4081     112099                                            Amen!   \n",
       "9    4081     122899                                        mama mia!   \n",
       "\n",
       "                                 item  rating  helpfulness gender  \\\n",
       "0                          McDonald's     4.0          3.0      M   \n",
       "1                           Taco Bell     1.0          4.0      M   \n",
       "2                             Wendy's     5.0          4.0      M   \n",
       "3  South Park: Bigger, Longer & Uncut     5.0          3.0      M   \n",
       "4                        American Pie     3.0          3.0      M   \n",
       "5                              Matrix     3.0          3.0      M   \n",
       "6                 Blair Witch Project     4.0          3.0      M   \n",
       "7                                 FOX     4.0          4.0      M   \n",
       "8                               Dogma     4.0          3.0      M   \n",
       "9                        Olive Garden     4.0          3.0      M   \n",
       "\n",
       "                category  item_id  item_price  user_city  \n",
       "0  Restaurants & Gourmet       41       30.74          4  \n",
       "1  Restaurants & Gourmet       74      108.30          4  \n",
       "2  Restaurants & Gourmet       84       69.00          4  \n",
       "3                 Movies       68      143.11          4  \n",
       "4                 Movies        6      117.89          4  \n",
       "5                 Movies       40       24.51          4  \n",
       "6                 Movies       12       44.00          4  \n",
       "7                  Media       25       80.00          4  \n",
       "8                 Movies       22       87.59          4  \n",
       "9  Restaurants & Gourmet       49       32.00          4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecommerce_df.head(10) # Display the first 10 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa4eb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2685 entries, 0 to 2684\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   userId       2685 non-null   int64  \n",
      " 1   timestamp    2685 non-null   int64  \n",
      " 2   review       2685 non-null   object \n",
      " 3   item         2685 non-null   object \n",
      " 4   rating       2685 non-null   float64\n",
      " 5   helpfulness  2685 non-null   float64\n",
      " 6   gender       2685 non-null   object \n",
      " 7   category     2685 non-null   object \n",
      " 8   item_id      2685 non-null   int64  \n",
      " 9   item_price   2685 non-null   float64\n",
      " 10  user_city    2685 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(4)\n",
      "memory usage: 230.9+ KB\n"
     ]
    }
   ],
   "source": [
    "ecommerce_df.info() # Display information about the dataset, including column names and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b15923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "categorical_features = ['gender', 'category', 'review']\n",
    "ecommerce_df[categorical_features] = encoder.fit_transform(ecommerce_df[categorical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "223eb8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             helpfulness    gender  category    review    rating\n",
      "helpfulness     1.000000  0.075947 -0.013408 -0.028259 -0.007523\n",
      "gender          0.075947  1.000000  0.022549 -0.037884 -0.034337\n",
      "category       -0.013408  0.022549  1.000000  0.001970 -0.163158\n",
      "review         -0.028259 -0.037884  0.001970  1.000000 -0.036118\n",
      "rating         -0.007523 -0.034337 -0.163158 -0.036118  1.000000\n"
     ]
    }
   ],
   "source": [
    "correlations = ecommerce_df[['helpfulness', 'gender', 'category', 'review', 'rating']].corr()\n",
    "print(correlations) #Finding out all the corrleated features regarding rating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ef9e61",
   "metadata": {},
   "source": [
    "# Explanation and Analysis on the correlations:\n",
    "\n",
    "Correlation is a statistical measure that is used to quantify the relationship between two variables. It helps us in understanding how changes in one variable will help us in determining the changes in other variables.\n",
    "\n",
    "1. The correlation coefficient between **helpfulness and rating** is -0.007523, which is close to 0. This indicates a very weak or no linear relationship between these two variables. It suggests that there is little to no impact of the helpfulness of a review on the rating assigned to it.\n",
    "\n",
    "2. The correlation between **gender and rating** is -0.034337, which is also close to 0. This suggests a very weak or non-linear relationship between gender and rating. It indicates that the gender of the person giving review has a negligible influence on the rating given to a product.\n",
    "\n",
    "3. The correlation between **category and rating** is -0.163158, which is closer to -1 than the previous correlations. This indicates a moderate negative correlation between category and rating. It suggests that the category of the product being reviewed has some impact on the assigned rating. It also means that the category and rating share an inverse relationship, i.e., if the value of one variable increases the other has to decrease.\n",
    "\n",
    "4. The correlation between **review and rating** is -0.036118, which is more than the correlation coefficient between gender and rating. It suggests that the specific words or phrases used in the review has a some amount of influence on the rating given to a product. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773698c7",
   "metadata": {},
   "source": [
    "## Analysis on the correlations:\n",
    "\n",
    "In order to figure out which are the most and least correlated features, we try to compare the values on a scale from -1 to 1. So, if the value of correlation is closer to -1 or 1 it is the most correlated values, Specifically speaking, values close to -1 indicate a strong negative correlation and values close to +1 indicate a strong positive correlation. On the contrary, if a value is closer to 0 then we can arrive to the conclusion that it is the least correlated value. And value 0 simply implies no correlation.\n",
    "\n",
    "From the values generated above, here is my conclusion:\n",
    "\n",
    "1. Category and review are the most correlated features. They will have a greater influence on the prediction.\n",
    "2. Helpfulness and gender are the least correlated features. They won't have any significant influence on the accuracy of the prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8000e0c0",
   "metadata": {},
   "source": [
    "### Understanding how the correlation will affect the final prediction results.\n",
    "\n",
    "1. Weak negative correlation between helpfulness and rating suggests little to no impact of the helpfulness of a review on the rating assigned to it. Including this feature in the regression model may not have an impact in the prediction accuracy for rating.\n",
    "\n",
    "2. Weak correlation between gender and rating implies that the gender of the reviewer may not have a significant impact on the rating prediction. Including this feature in the model may not significantly improve the prediction results.\n",
    "\n",
    "3. Moderate negative correlation between category and rating indicates that the category of the product being reviewed may have a notable effect on the predicted rating. Moreover, Including this feature in the model can enhance the prediction accuracy, especially if we have distinct rating patterns among a differrent product categories.\n",
    "\n",
    "4. Moderate correlation between review and rating suggests that the specific words or phrases used in the review will have a reasonable influence on the rating prediction. Including this feature in the model may improve the prediction results.\n",
    "\n",
    "Overall, considering the correlations, it seems that review and product category are the most informative features for predicting the rating. Gender and helpfulness itself may have less impact on the final rating prediction. \n",
    "\n",
    "However, it is important to note that correlation does not imply causation, and there may be other factors influencing the prediction results that are not captured by these correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4myP5igslA_Y",
   "metadata": {
    "id": "4myP5igslA_Y"
   },
   "source": [
    "### Split Training and Testing Data\n",
    "* Machine learning models are trained to help make predictions for the future. Normally, we need to randomly split the dataset into training and testing sets, where we use the training set to train the model, and then leverage the well-trained model to make predictions on the testing set.\n",
    "* To further investigate whether the size of the training/testing data affects the model performance, please random split the data into training and testing sets with different sizes:\n",
    "    * Case 1: training data containing 10% of the entire data;\n",
    "    * Case 2: training data containing 90% of the entire data.\n",
    "* Print the shape of training and testing sets in the two cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "JIDMig9blA_Y",
   "metadata": {
    "id": "JIDMig9blA_Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1:\n",
      "Shape of training set: (268, 4)\n",
      "Shape of the test set: (2417, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming that X contains the features and y contains the target variable i.e., rating\n",
    "X = ecommerce_df[['helpfulness', 'gender', 'category', 'review']]\n",
    "y = ecommerce_df['rating']\n",
    "\n",
    "# Case 1: Training data containing 10% of the entire data\n",
    "#test size will be 0.9\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, y, test_size=0.9, random_state=142)\n",
    "print(\"Case 1:\")\n",
    "print(\"Shape of training set:\",X_train_1.shape)\n",
    "print(\"Shape of the test set:\",X_test_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ccc968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 2:\n",
      "Shape of the training set: (2416, 4)\n",
      "Shape of the test set: (269, 4)\n"
     ]
    }
   ],
   "source": [
    "# Assuming X contains the features and y contains the target variable i.e., rating\n",
    "X = ecommerce_df[['helpfulness', 'gender', 'category', 'review']]\n",
    "y = ecommerce_df['rating']\n",
    "\n",
    "# Case 2: Training data containing 90% of the entire data\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X, y, test_size=0.1, random_state=142)\n",
    "\n",
    "print(\"Case 2:\")\n",
    "print(\"Shape of the training set:\",X_train_2.shape)\n",
    "print(\"Shape of the test set:\",X_test_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DjSsgT0BlA_Y",
   "metadata": {
    "id": "DjSsgT0BlA_Y"
   },
   "source": [
    "### Train Linear Regression Models with Feature Selection under Cases 1 & 2\n",
    "* When training a machine learning model for prediction, we may need to select the most important/correlated input features for more accurate results.\n",
    "* To investigate whether feature selection affects the model performance, please select two most correlated features and two least correlated features regarding rating, respectively.\n",
    "* Train four linear regression models by following the conditions:\n",
    "    - (model-a) using the training/testing data in case 1 with two most correlated input features\n",
    "    - (model-b) using the training/testing data in case 1 with two least correlated input features\n",
    "    - (model-c) using the training/testing data in case 2 with two most correlated input features\n",
    "    - (model-d) using the training/testing data in case 2 with two least correlated input features\n",
    "* By doing this, we can verify the impacts of the size of traing/testing data on the model performance via comparing model-a and model-c (or model-b and model-d); meanwhile the impacts of feature selection can be validated via comparing model-a and model-b (or model-c and model-d).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "DASzPUATlA_Z",
   "metadata": {
    "id": "DASzPUATlA_Z"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in this section we are supposed to build four models\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model_a = LinearRegression()\n",
    "model_a.fit(X_train_1[['category', 'review']], y_train_1) #model-a using two most correlated input features.\n",
    "\n",
    "model_b = LinearRegression()\n",
    "model_b.fit(X_train_1[['helpfulness', 'gender']], y_train_1) #model-b using two least correlated input features.\n",
    "\n",
    "model_c = LinearRegression()\n",
    "model_c.fit(X_train_2[['category', 'review']], y_train_2) #model-c using two most correlated input features.\n",
    "\n",
    "model_d = LinearRegression()\n",
    "model_d.fit(X_train_2[['helpfulness', 'gender']], y_train_2) #model-d using two least correlated input features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KATSn7hYlA_Z",
   "metadata": {
    "id": "KATSn7hYlA_Z"
   },
   "source": [
    "### Evaluate Models\n",
    "* Evaluate the performance of the four models with two metrics, including MSE and Root MSE\n",
    "* Print the results of the four models regarding the two metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fU8GPS9lA_Z",
   "metadata": {
    "id": "4fU8GPS9lA_Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A with 10% training data, most correlated features:\n",
      "MSE: 1.7690740179517055\n",
      "RMSE: 1.3300654186737229\n"
     ]
    }
   ],
   "source": [
    "                                    #Performance of Model A\n",
    "y_pred_a = model_a.predict(X_test_1[['category', 'review']])\n",
    "mse_a = mean_squared_error(y_test_1, y_pred_a)\n",
    "rmse_a = mse_a ** 0.5\n",
    "print(\"Model A with 10% training data, most correlated features:\")\n",
    "print(\"MSE:\", mse_a)\n",
    "print(\"RMSE:\", rmse_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b571c879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model B with 10% training data, least correlated features:\n",
      "MSE: 1.8412549895856636\n",
      "RMSE: 1.356928513071217\n"
     ]
    }
   ],
   "source": [
    "                                    #Performance of Model B\n",
    "y_pred_b = model_b.predict(X_test_1[['helpfulness', 'gender']])\n",
    "mse_b = mean_squared_error(y_test_1, y_pred_b)\n",
    "rmse_b = mse_b ** 0.5\n",
    "print(\"Model B with 10% training data, least correlated features:\")\n",
    "print(\"MSE:\", mse_b)\n",
    "print(\"RMSE:\", rmse_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "988bca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model C with 90% training data, most correlated features:\n",
      "MSE: 1.7588975359805048\n",
      "RMSE: 1.3262343442923294\n"
     ]
    }
   ],
   "source": [
    "                                    #Performance of Model C\n",
    "y_pred_c = model_c.predict(X_test_2[['category', 'review']])\n",
    "mse_c = mean_squared_error(y_test_2, y_pred_c)\n",
    "rmse_c = mse_c ** 0.5\n",
    "print(\"Model C with 90% training data, most correlated features:\")\n",
    "print(\"MSE:\", mse_c)\n",
    "print(\"RMSE:\", rmse_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a6bb4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model D with 90% training data, least correlated features:\n",
      "MSE: 1.8109460127732369\n",
      "RMSE: 1.3457139416581954\n"
     ]
    }
   ],
   "source": [
    "                                    #Performance of Model D\n",
    "y_pred_d = model_d.predict(X_test_2[['helpfulness', 'gender']])\n",
    "mse_d = mean_squared_error(y_test_2, y_pred_d)\n",
    "rmse_d = mse_d ** 0.5\n",
    "print(\"Model D with 90% training data, least correlated features:\")\n",
    "print(\"MSE:\", mse_d)\n",
    "print(\"RMSE:\", rmse_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y9jx-eY6lA_a",
   "metadata": {
    "id": "Y9jx-eY6lA_a"
   },
   "source": [
    "### Visualize, Compare and Analyze the Results\n",
    "* Visulize the results, and perform ___insightful analysis___ on the obtained results. For better visualization, you may need to carefully set the scale for the y-axis.\n",
    "* Normally, the model trained with most correlated features and more training data will get better results. Do you obtain the similar observations? If not, please ___explain the possible reasons___."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3TNAIGDilA_a",
   "metadata": {
    "id": "3TNAIGDilA_a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data for MSE and RMSE values rounded off to 3 dp.\n",
    "mse_values = [1.769, 1.841, 1.759, 1.811]\n",
    "rmse_values = [1.330, 1.357, 1.326, 1.346]\n",
    "model_names = ['Model A', 'Model B', 'Model C', 'Model D']\n",
    "\n",
    "data = {'Model': model_names, 'MSE': mse_values, 'RMSE': rmse_values}\n",
    "model_df = pd.DataFrame(data)\n",
    "\n",
    "# Set the style of the plot\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Bar plots for MSE and RMSE\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x='Model', y='MSE', data=model_df)\n",
    "plt.title('MSE')\n",
    "plt.ylim(1.6, 1.9)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x='Model', y='RMSE', data=model_df)\n",
    "plt.title('RMSE')\n",
    "plt.ylim(1.3, 1.4)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b23ef3",
   "metadata": {},
   "source": [
    "From the provided information, we can deduce that the models trained with the most correlated features and more training data (Model A and Model C) have lower values of both Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) compared to the models trained with the least correlated features and less training data (Model B and Model D). This is consistent with the expectation that models trained with more relevant features and more data tend to perform better.\n",
    "\n",
    "*******************************************************************************************************************************\n",
    "However, if this wasn't the case and Model A and Model C didn't perform better than Model B and Model D, then the possible reasons for these observations can include:\n",
    "\n",
    "1. **Overfitting**: Models A and C can have overfit the training data due to the complexity introduced by using the most correlated features and the larger training data size. Overfitting can lead to poor generalization on unseen data, resulting in higher MSE and RMSE values.\n",
    "\n",
    "2. **Relevance of the Feature**: The most correlated features used in Models A and C may not be the most informative or relevant features for the prediction task. Correlation does not necessarily imply causation, and using less correlated features that capture the underlying patterns in the data more effectively can lead to better performance.\n",
    "\n",
    "3. **Quality of Data**: The quality and representativeness of the training data can have a significant impact on model performance. If the larger training data used in Models C and D contains noise, outliers, or irrelevant instances, it can negatively affect the model's performance.\n",
    "\n",
    "It's crucial for a Data Analyst to carefully analyze and evaluate these factors to make informed decisions about feature selection, data preparation, and model training."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
